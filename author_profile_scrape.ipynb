{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nama Penulis: RIRIEN PRIHANDARINI\n",
      "Afiliasi tidak ditemukan.\n",
      "SINTA ID tidak ditemukan.\n",
      "Topik Penelitian tidak ditemukan.\n",
      "SINTA Score Overall: 393\n",
      "SINTA Score 3Yr: 174\n",
      "\n",
      "Publikasi Terbaru (Halaman 1):\n",
      "- Effect of formulated microorganisms, goat fertilizer and banana webs extract in organic kale (Brassica oleracea) (Tahun: 2021)\n",
      "- STUDY OF THE UTILIZATION OF RIM (REFRESH MICROORGANISM) IN SUGARCANE (Tahun: 2020)\n",
      "- Formulation of microorganisms for cane plants (Tahun: 2020)\n",
      "Jumlah Halaman tidak ditemukan.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL profil penulis\n",
    "base_url = \"https://sinta.kemdikbud.go.id/authors/profile/5983346\"\n",
    "\n",
    "# Mengirim permintaan GET ke URL\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.121 Safari/537.36\"\n",
    "}\n",
    "\n",
    "def get_page_content(url):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return BeautifulSoup(response.content, \"html.parser\")\n",
    "    else:\n",
    "        print(\"Gagal mengambil halaman, status code:\", response.status_code)\n",
    "        return None\n",
    "\n",
    "# Parsing halaman pertama\n",
    "soup = get_page_content(base_url)\n",
    "\n",
    "if soup:\n",
    "    # Mengambil nama penulis\n",
    "    author_name = soup.find(\"h3\")\n",
    "    if author_name:\n",
    "        print(\"Nama Penulis:\", author_name.text.strip())\n",
    "    else:\n",
    "        print(\"Nama Penulis tidak ditemukan.\")\n",
    "\n",
    "    # Mengambil afiliasi\n",
    "    affiliation = soup.find(\"a\", class_=\"el el-map-marker mr-1\")\n",
    "    if affiliation:\n",
    "        print(\"Afiliasi:\", affiliation.text.strip())\n",
    "    else:\n",
    "        print(\"Afiliasi tidak ditemukan.\")\n",
    "\n",
    "    # Mengambil SINTA ID\n",
    "    sinta_id = soup.find(\"a\", string=\"SINTA ID :\")\n",
    "    if sinta_id:\n",
    "        print(\"SINTA ID:\", sinta_id.text.strip())\n",
    "    else:\n",
    "        print(\"SINTA ID tidak ditemukan.\")\n",
    "\n",
    "    # Mengambil topik penelitian\n",
    "    subjects = soup.find_all(\"li\", class_=\"subject-list\")\n",
    "    if subjects:\n",
    "        print(\"Topik Penelitian:\")\n",
    "        for subject in subjects:\n",
    "            print(\"-\", subject.text.strip())\n",
    "    else:\n",
    "        print(\"Topik Penelitian tidak ditemukan.\")\n",
    "\n",
    "    # Mengambil total SINTA score\n",
    "    sinta_scores = soup.find_all(\"div\", class_=\"pr-num\")\n",
    "    if len(sinta_scores) >= 2:\n",
    "        print(\"SINTA Score Overall:\", sinta_scores[0].text.strip())\n",
    "        print(\"SINTA Score 3Yr:\", sinta_scores[1].text.strip())\n",
    "    else:\n",
    "        print(\"SINTA Score tidak ditemukan.\")\n",
    "\n",
    "    # Mengambil publikasi terbaru dari semua halaman\n",
    "    current_page = 1\n",
    "    while True:\n",
    "        print(f\"\\nPublikasi Terbaru (Halaman {current_page}):\")\n",
    "        publications = soup.find_all(\"div\", class_=\"ar-list-item\")\n",
    "        if publications:\n",
    "            for pub in publications:\n",
    "                title = pub.find(\"div\", class_=\"ar-title\").a\n",
    "                year = pub.find(\"a\", class_=\"ar-year\")\n",
    "                if title and year:\n",
    "                    print(f\"- {title.text.strip()} (Tahun: {year.text.strip()})\")\n",
    "        else:\n",
    "            print(\"Publikasi tidak ditemukan.\")\n",
    "\n",
    "        # Cek apakah ada halaman berikutnya\n",
    "        next_page_link = soup.find(\"li\", class_=\"page-item \")\n",
    "        if next_page_link and next_page_link.a:\n",
    "            next_page_url = base_url + next_page_link.a[\"href\"]\n",
    "            soup = get_page_content(next_page_url)\n",
    "            current_page += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # Mengambil jumlah halaman yang tersedia\n",
    "    pagination = soup.find(\"div\", class_=\"pagination-text\")\n",
    "    if pagination:\n",
    "        pages_text = pagination.text.strip()\n",
    "        print(\"Jumlah Halaman Tersedia:\", pages_text)\n",
    "    else:\n",
    "        print(\"Jumlah Halaman tidak ditemukan.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
